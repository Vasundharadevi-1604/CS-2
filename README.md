# 🧠 Generative AI in Cybersecurity – A Comprehensive Review of LLM Applications and Vulnerabilities

📌 **Author:** P. Vasundhara Devi  
📌 **Program:** Cyber Security  
📌 **Date:** 01/09/2025  

---

## 📖 Project Overview  
This project explores how Generative Artificial Intelligence (AI) and Large Language Models (LLMs) can enhance cybersecurity through applications like threat intelligence, phishing detection, and malware analysis. It also addresses emerging risks such as prompt injection and data leakage by implementing the Lightweight LLM Security Evaluation and Mitigation Framework (LSEMF) — a Python-based solution designed to detect, prevent, and evaluate vulnerabilities in LLMs while maintaining model performance and reliability.

---

## 🔒 Key Features  
- Prompt Filtering Module:
Blocks malicious or unsafe inputs before they reach the LLM.

- Retrieval-Based Reinforcement Module:
Enhances model reliability using context retrieval from a verified knowledge base.

- LLM Query Module:
Ensures only validated prompts are processed and generates safe, relevant responses.

- Experimental Metrics Module:
Evaluates performance using metrics such as Accuracy, Precision, Injection Success Rate (ISR), and Response Utility.  

---

## ⚙️ Methodology
To enhance the security of Large Language Models (LLMs) while maintaining high model performance and usability.
Core Components:

- Prompt Filtering – Detects unsafe or adversarial prompts.

- Retrieval-Based Reinforcement – Verifies LLM outputs with trusted references using TF-IDF similarity.

- Evaluation Metrics – Quantitatively measures improvements in accuracy and attack resilience.

Expected Outcomes:

- 60% reduction in Injection Success Rate (ISR)

- +3% improvement in accuracy

- +4% increase in precision
  
---

## 📊 Discussion
- The LSEMF framework balances security and performance, providing a robust and practical foundation for LLM use in cybersecurity.

- Prompt filtering and retrieval-based reinforcement significantly reduce malicious prompt risks.

- Results confirm that enhanced safety can be achieved without major loss in model usability.

---

## 📈 Future Enhancements
- Integration with real-world cybersecurity datasets (e.g., CICIDS 2023)

- Real-time threat monitoring and adaptive prompt filtering

- Extension to multimodal LLMs (text + code)

- Benchmarking using standardized LLM safety datasets

---

## 🧾 Reference
- Research Paper: Generative AI in Cybersecurity - A Comprehensive Review of LLM Applications and Vulnerabilities by Ferrag, M. A., Maglaras, L., et al.
- Journal: Internet of Things and Cyber–Physical Systems (KeAi / Elsevier)
https://www.sciencedirect.com/science/article/pii/S2667345225000082
